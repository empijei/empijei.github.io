<html>
<head>
<style type="text/css">
body {
  margin: 0;
  padding: 0;
}
#container {
  position: fixed;
  height: 100%;
  width: 100%;
}
canvas {
  height: auto !important;
  width: auto !important;
  max-height: 100%;
  max-width: 100%;
}
</style>
</head>
<body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/88/three.min.js"></script>
<script id="vertexShader" type="x-shader/x-vertex">
    void main() {
        gl_Position = vec4( position, 1.0 );
    }
</script>
<script id="fragmentShader" type="x-shader/x-fragment">
precision highp float;
uniform highp vec2 u_resolution;
uniform float u_time;
uniform sampler2D u_texture;
uniform float u_normBlue;
uniform float u_testBlue;
uniform float u_normRed;
uniform float u_testRed;
uniform float u_normGreen;
uniform float u_testGreen;

vec3 rgb2hsv(vec3 c) {
  vec4 K = vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);
  vec4 p = mix(vec4(c.bg, K.wz), vec4(c.gb, K.xy), step(c.b, c.g));
  vec4 q = mix(vec4(p.xyw, c.r), vec4(c.r, p.yzx), step(p.x, c.r));

  float d = q.x - min(q.w, q.y);
  float e = 1.0e-10;
  return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + e)), d / (q.x + e), q.x);
}

vec3 hsv2rgb(vec3 c) {
  vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
  vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
  return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
}

vec3 correctFilter(vec3 hsl){
  vec2 prev, cur;
  prev=vec2(1.0,1.0);
  if (hsl.x < prev.x){
     cur=prev;
     prev=vec2(u_normBlue,u_testBlue);
  }
  if (hsl.x < prev.x){
    cur=prev;
    prev=vec2(0.33,0.33);
  }
  if (hsl.x < prev.x){
    cur=prev;
    prev=vec2(u_normGreen,u_testGreen);
  }
  if (hsl.x < prev.x){
    cur=prev;
    prev=vec2(u_normRed,u_testRed);
  }
  if (hsl.x < prev.x){
   cur=prev;
   prev=vec2(0.0,0.0);
  }

  float coeff = (hsl.x - prev.x) / (cur.x - prev.x);
  hsl.x = (coeff*(cur.y-prev.y) + prev.y);

  //Saturation
  prev = vec2(0.0,0.0);
  cur = vec2(0.2,0.4);
  if (hsl.y > cur.x){
    prev=cur;
    cur=vec2(1.0,0.99);
  }

  coeff = (hsl.y - prev.x) / (cur.x - prev.x);
  hsl.y = (coeff*(cur.y-prev.y) + prev.y);

  return hsl;
}

void main() {
  vec2 uv = gl_FragCoord.xy / min(u_resolution.y, u_resolution.x);
  vec3 colour = texture2D(u_texture, uv).rgb;
  colour *= step(uv.x, 1.0);
  colour *= step(uv.y, 1.0);
  colour *= step(0.0, uv.x);
  colour *= step(0.0, uv.y);
  vec3 hsl = rgb2hsv(vec3(colour.r,colour.g,colour.b));
  hsl=correctFilter(hsl);
  colour.rgb = hsv2rgb(hsl);
  gl_FragColor = vec4(colour,1.0);
}
</script>

<div id="container"></div>
<div id="image"></div>
<video id="monitor" autoplay width="1024" height="1024" style="visibility: hidden; float:left; display:none;"></video>
<canvas id="videoImage" width="1024" height="1024" style="visibility: hidden; float:left; display:none;"></canvas>

<script>
let container;
let camera, scene, renderer;
let uniforms;
let texture;
let video, videoImage, videoImageContext, videoTexture;

function init() {
  container = document.getElementById( 'container' );
  video = document.getElementById( 'monitor' );
  videoImage = document.getElementById( 'videoImage' );
  videoImageContext = videoImage.getContext( '2d' );
  // background color if no video present
  videoImageContext.fillStyle = '#000000';
  videoImageContext.fillRect( 0, 0, videoImage.width, videoImage.height );
  videoTexture = new THREE.Texture( videoImage );
  camera = new THREE.Camera();
  camera.position.z = 1;

  scene = new THREE.Scene();

  var geometry = new THREE.PlaneBufferGeometry( 2, 2 );

  // Parse params from url
  let hashvalues = {};
  if (window.location.hash) {
    window.location.hash.substr(1).split("&").forEach((kv)=>{
      let [k,v] = kv.split("=");
      hashvalues[k] = v/360;
    });
  }
  console.log("Params:", hashvalues);

  uniforms = {
    u_time: { type: "f", value: 1.0 },
    u_resolution: { type: "v2", value: new THREE.Vector2() },
    u_texture: { type: "t", value: videoTexture },

    u_normBlue:  { type: "f", value: hashvalues["nb"]},
    u_testBlue:  { type: "f", value: hashvalues["tb"]},
    u_normGreen: { type: "f", value: hashvalues["ng"]},
    u_testGreen: { type: "f", value: hashvalues["tg"]},
    u_normRed:   { type: "f", value: hashvalues["nr"]},
    u_testRed:   { type: "f", value: hashvalues["tr"]},
  };

  var material = new THREE.ShaderMaterial( {
    uniforms: uniforms,
    vertexShader: document.getElementById( 'vertexShader' ).textContent,
    fragmentShader: document.getElementById( 'fragmentShader' ).textContent
  } );
  material.extensions.derivatives = true;

  var mesh = new THREE.Mesh( geometry, material );
  scene.add( mesh );

  renderer = new THREE.WebGLRenderer({ preserveDrawingBuffer: true });
  renderer.setPixelRatio( 2 );

  container.appendChild( renderer.domElement );

  onWindowResize();
  window.addEventListener( 'resize', onWindowResize, false );
}

function onWindowResize( event ) {
  let w = window.innerWidth;
  let h = window.innerHeight;
  renderer.setSize( w, h );
  uniforms.u_resolution.value.x = renderer.domElement.width;
  uniforms.u_resolution.value.y = renderer.domElement.height;
}
function animate() {
  requestAnimationFrame( animate );
  render();
}
function render() {
  uniforms.u_time.value += 0.01;
  if ( video.readyState === video.HAVE_ENOUGH_DATA ) {
    videoImageContext.drawImage( video, 0, 0, videoImage.width, videoImage.height);
    if ( videoTexture ) videoTexture.needsUpdate = true;
  }
  renderer.render( scene, camera );
}
</script>
<script>
navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia;
window.URL = window.URL || window.webkitURL;
var camvideo = document.getElementById('monitor');
navigator.mediaDevices.getUserMedia({video: { facingMode: "environment" } }).then( function(stream){
  camvideo.srcObject = stream;
  camvideo.onerror = function(e) { stream.stop(); };
  stream.onended = function noStream(e) {
    var msg = 'No camera available.';
    if (e.code == 1) { msg = 'User denied access to use camera.'; }
    document.getElementById('errorMessage').textContent = msg;
  }
});
init();
animate();
</script>
</body>
</html>
